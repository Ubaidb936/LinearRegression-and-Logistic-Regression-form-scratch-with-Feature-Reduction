{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3307ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a36ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnlogreg(X,Y):\n",
    "    # X is the data matrix of shape (m,n)\n",
    "    # Y is are the target labels (+1,-1) of shape (m,)\n",
    "    # function should return w of shape (n,)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    NumberOfDataPoints, NumberOfFeatures = X.shape\n",
    "    \n",
    "    Y_X = np.ones((NumberOfDataPoints, NumberOfFeatures))\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        Y_X[i] = Y[i]*X[i]\n",
    "    \n",
    "    \n",
    "    ##Intilizing the weight vector\n",
    "    \n",
    "    W = np.zeros(NumberOfFeatures)\n",
    "    \n",
    "    STEP_SIZE = 0.00001\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        X_W = np.matmul(X, W)\n",
    "        \n",
    "        Y_X_W = Y * X_W\n",
    "        \n",
    "        sig_Y_X_W = 1/(1 + np.exp(-Y_X_W))\n",
    "        \n",
    "        t = (1- sig_Y_X_W)\n",
    "        \n",
    "        S_MAT = np.ones((NumberOfDataPoints, NumberOfFeatures))\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            S_MAT[i] = t[i]*Y_X[i]\n",
    "        \n",
    "        # S_MAT = t@X\n",
    "            \n",
    "        S = S_MAT.sum(axis = 0)\n",
    "        \n",
    "        W_NEW = W + STEP_SIZE * S\n",
    "        \n",
    "        X_W_NEW = np.matmul(X, W_NEW)\n",
    "        \n",
    "        Y_X_W_NEW = Y * X_W_NEW\n",
    "        \n",
    "        sig_Y_X_W_NEW = 1/(1 + np.exp(-Y_X_W_NEW))\n",
    "        \n",
    "        #code to check convergence\n",
    "        loss = np.sum(-np.log(sig_Y_X_W))\n",
    "        lossNEW = np.sum(-np.log(sig_Y_X_W_NEW))\n",
    "        \n",
    "    \n",
    "        if abs(loss - lossNEW) < 0.1:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        W = W_NEW\n",
    "        \n",
    "    return W\n",
    "        \n",
    "        \n",
    "def predictlogreg(X,w):\n",
    "    # X is the (testing) data of shape (m,n)\n",
    "    # w are the weights learned in logistic regression\n",
    "    # function should return Y, the predicted values of shape (m,) (all values either +1 or -1)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    linear_pred = np.dot(X, w)\n",
    "    sig_Y_X_W = 1/(1 + np.exp(-linear_pred))\n",
    "    \n",
    "    preds = [-1 if y < 0.5 else 1 for y in sig_Y_X_W]\n",
    "    \n",
    "    return np.array(preds)\n",
    "    \n",
    "def testlogreg(X,Y,w):\n",
    "    # X and Y are the testing data\n",
    "    # w are the weights from logistic regression\n",
    "    # returns the mean squared error\n",
    "    Ypred = np.sign(predictlogreg(X,w)) ## should be +1/-1, but incase they are not\n",
    "    \n",
    "    return (Ypred!=np.sign(Y)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2fb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# now code to check the training and testing errors:\n",
    "wclass = learnlogreg(trainX,trainYclass)\n",
    "print('training mean classification error: ',testlogreg(trainX,trainYclass,wclass))\n",
    "print('testing mean classification error:  ',testlogreg(testX,testYclass,wclass))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
